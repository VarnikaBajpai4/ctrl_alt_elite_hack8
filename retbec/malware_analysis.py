import json
import re
import os
import sys
from dotenv import load_dotenv
import google.generativeai as genai

# Load Gemini API key
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

FUNC_REGEX = re.compile(
    r"(?:[a-zA-Z_][\w\s\*]+)?\s+([a-zA-Z_]\w*)\s*\([^)]*\)\s*\{(?:[^{}]*|\{[^}]*\})*\}",
    re.DOTALL
)


def extract_functions(code):
    """Extract and rank functions by size (longest first)"""
    matches = list(FUNC_REGEX.finditer(code))
    ranked = sorted(matches, key=lambda m: len(m.group(0)), reverse=True)
    return [(m.group(1), m.group(0)) for m in ranked[:5]]  # Top 5 largest functions


def analyze_malware(mal_dir):
    c_files = [f for f in os.listdir(mal_dir) if f.endswith('.c')]
    if not c_files:
        return {"error": "No C file found"}

    c_path = os.path.join(mal_dir, c_files[0])
    f_path = os.path.join(mal_dir, "features.json")

    if not os.path.exists(f_path):
        return {"error": "features.json missing"}
    if not os.path.exists(c_path):
        return {"error": "C code missing"}

    with open(c_path, "r", errors="ignore") as f:
        c_code = f.read()

    with open(f_path, "r") as f:
        features = json.load(f)

    model = genai.GenerativeModel("models/gemini-1.5-flash")

    # Extract top longest functions
    top_functions = extract_functions(c_code)
    selected_code = "\n\n".join(f"// Function: {name}\n{body}" for name, body in top_functions)

    prompt = f"""
You are a world-class reverse engineer and static malware analyst. Your task is to deeply analyze the C code **function-by-function** and combine that with extracted static features to classify the binary as **malicious or benign**.

---

### Phase 1: Function-Level Analysis

For **each function** in the C code:
- Summarize what the function does (e.g., drops a file, opens registry keys, allocates memory).
- Determine **if the function is suspicious** based on API sequences, persistence behavior, injection, or obfuscation.
- Label each function as: "benign_use", "suspicious_chain", or "malicious_intent".

Use only these labels and justify each with evidence.

---

### Phase 2: Global Behavioral Patterns

After analyzing all functions, report:
- Behavior chains across functions (e.g., one function allocates memory, another injects).
- Any stealthy patterns (e.g., avoids UI calls, uses raw socket, high entropy strings, or custom PE loader).

---

### Phase 3: Feature Reconfirmation

Now consider the `features.json` as **supporting evidence**. Look for:
- High entropy, suspicious section names.
- No digital signature, subsystem info, presence of anti-debug, or zero export count.
- Raise or lower your confidence based on whether the features align with the code logic.

**If the binary is:**
- Digitally signed (`has_signature` = true),
- Subsystem = `"WINDOWS_GUI"` or `"WINDOWS_CUI"`,
- Uses APIs typical of benign services like `CreateServiceW`, `SetServiceStatus`, `RegSetValueExW` under `HKLM\\System\\CurrentControlSet\\Services`, `OpenEventLogW`, etc.,

Then assume it may be a **legitimate Windows system service or installer**.

→ **In such cases, subtract `-0.3` from the final malware score**, unless malicious indicators (e.g., `VirtualAlloc`, `CreateRemoteThread`, heavy obfuscation, or hidden payloads) are also clearly present.

---

### Helper Rule for Legitimate Services

If the binary’s function pattern matches **benign service behavior**, such as:
- Setting registry keys under `HKLM\\System\\CurrentControlSet\\Services`
- Using `CreateServiceW`, `RegisterServiceCtrlHandlerW`, `ReportEventW`
- Accessing Windows Event Logs
- Loading cryptographic certificates (e.g., `CryptQueryObject`, `CertFindCertificateInStore`)

Then **tag that function** as `"benign_use"` unless it's directly followed by suspicious chains or stealth indicators.

---

### Scoring Logic

- Start `malware_probability = 0.0`
- Add `+0.3` for each **confirmed malicious function or suspicious chain**
- Add `+0.15` for stealth indicators (e.g., evasion, entropy > 6.5, avoids UI)
- Subtract `-0.3` if service pattern above is matched and no injection/obfuscation found
- Cap score to [0.0, 1.0]

---

### Final Output Format (strict)

Return ONLY this JSON format:

{{
  "malware_probability": <float between 0.0 and 1.0>,
  "suspicious_indicators": [<list of API sequences or suspicious behavior summaries>],
  "behavioral_patterns": [<summary of behavior like dropper, injector, persistence, stealth>],
  "potential_impact": <description of actual threat OR benign system purpose>,
  "confidence_score": <float between 0.0 and 1.0>,
  "function_analysis": [
    {{
      "function_name": "<extracted name or signature>",
      "summary": "<1-2 sentence summary>",
      "classification": "<benign_use | suspicious_chain | malicious_intent>",
      "evidence": ["API: CreateFileW", "Calls RegSetValueExW on HKCU\\\\Run", ...]
    }},
    ...
  ]
}}


---

C code:
{selected_code}

Features:
{json.dumps(features, indent=2)}
"""


    try:
        response = model.generate_content(prompt)
        match = re.search(r"\{[\s\S]*\}", response.text)
        if match:
            return json.loads(match.group(0))
        return {"error": "Invalid response format from Gemini"}
    except Exception as e:
        return {"error": f"Analysis failed: {str(e)}"}


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python malware_analysis.py <path-to-retdec-output-dir>")
        sys.exit(1)
    result = analyze_malware(sys.argv[1])
    print(json.dumps(result, indent=2))