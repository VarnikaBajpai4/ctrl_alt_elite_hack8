import json
import re
import os
import sys
from dotenv import load_dotenv
import google.generativeai as genai

# Load environment variables
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

def analyze_malware(mal_dir):
    # Find the C file in the directory
    c_files = [f for f in os.listdir(mal_dir) if f.endswith('.c')]
    if not c_files:
        return {"error": "No C file found in the directory"}
    
    c_file = c_files[0]
    features_path = os.path.join(mal_dir, "features.json")
    c_code_path = os.path.join(mal_dir, c_file)

    if not os.path.exists(features_path):
        return {"error": f"Features file not found at {features_path}"}
    if not os.path.exists(c_code_path):
        return {"error": f"C file not found at {c_code_path}"}

    # Load the features JSON
    with open(features_path, "r") as f:
        features = json.load(f)

    # Load and check C code size
    with open(c_code_path, "r", errors="ignore") as f:
        c_code = f.read()
        lines = c_code.splitlines()
        if len(lines) > 50000:
            c_code = "\n".join(lines[:50000]) + "\n// ... [Code truncated due to size limit] ..."

    # Construct the prompt
    prompt = f"""
    You are a cybersecurity expert analyzing a binary sample. Analyze the provided code and features to determine if it's malicious or benign.

    Consider these aspects:
    1. Suspicious Indicators:
       - Unusual API calls (VirtualAlloc, WriteProcessMemory, etc.)
       - Obfuscation techniques
       - Anti-debugging measures
       - Network communication patterns
       - File system operations
       - Process manipulation
       - Data exfiltration attempts

    2. Benign Indicators:
       - Standard system operations
       - Normal file handling
       - Legitimate network communication
       - Expected process behavior
       - Common library usage
       - Clear, readable code structure

    3. Overall Assessment:
       - Malware probability (0-1)
       - Key findings (both suspicious and benign)
       - Behavioral patterns
       - Potential impact (if malicious) or intended purpose (if benign)

    Return ONLY a JSON object with these fields:
    {{
      "malware_probability": <float between 0 and 1>,
      "suspicious_indicators": <list of suspicious findings>,
      "behavioral_patterns": <list of observed behaviors>,
      "potential_impact": <string describing impact or purpose>,
      "confidence_score": <float between 0 and 1 indicating analysis confidence>
    }}

    C code:
    {c_code}

    Features:
    {json.dumps(features, indent=2)}
    """

    try:
        model = genai.GenerativeModel("models/gemini-1.5-flash")
        response = model.generate_content(prompt)

        match = re.search(r"\{[\s\S]*\}", response.text)
        if match:
            return json.loads(match.group(0))
        return {"error": "Invalid response format from Gemini"}

    except Exception as e:
        return {"error": f"Analysis failed: {str(e)}"}

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python malware_analysis.py <path-to-retdec-output-dir>")
        sys.exit(1)
    
    result = analyze_malware(sys.argv[1])
    print(json.dumps(result, indent=2))