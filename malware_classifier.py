import os
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
import re
from pathlib import Path
import chardet

def is_binary_file(file_path):
    """Check if a file is binary."""
    try:
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(1024), b''):
                if b'\0' in chunk:
                    return True
        return False
    except Exception:
        return True

def detect_encoding(file_path):
    """Detect file encoding."""
    try:
        with open(file_path, 'rb') as f:
            raw_data = f.read()
            result = chardet.detect(raw_data)
            return result['encoding']
    except Exception:
        return None

def extract_features(file_path):
    """Extract features from a script file."""
    try:
        if is_binary_file(file_path):
            # For binary files, extract basic features only
            with open(file_path, 'rb') as f:
                content = f.read()
                return {
                    'length': len(content),
                    'num_lines': 0,
                    'num_spaces': 0,
                    'num_tabs': 0,
                    'num_commands': 0,
                    'num_urls': 0,
                    'num_ips': 0,
                    'num_hex': len(re.findall(rb'0x[0-9a-fA-F]+', content)),
                    'num_base64': len(re.findall(rb'[A-Za-z0-9+/]{4,}={0,2}', content)),
                    'content': '',  # Empty content for binary files
                    'is_binary': 1
                }
        
        # Try to detect encoding
        encoding = detect_encoding(file_path)
        if not encoding:
            encoding = 'utf-8'
            
        with open(file_path, 'r', encoding=encoding, errors='replace') as f:
            content = f.read()
        
        # Basic features
        features = {
            'length': len(content),
            'num_lines': len(content.split('\n')),
            'num_spaces': content.count(' '),
            'num_tabs': content.count('\t'),
            'num_commands': len(re.findall(r'\b(cmd|powershell|wscript|regsvr32|rundll32|mshta|certutil|bitsadmin|net|netstat|tasklist|ipconfig)\b', content.lower())),
            'num_urls': len(re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', content)),
            'num_ips': len(re.findall(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b', content)),
            'num_hex': len(re.findall(r'0x[0-9a-fA-F]+', content)),
            'num_base64': len(re.findall(r'[A-Za-z0-9+/]{4,}={0,2}', content)),
            'content': content,
            'is_binary': 0
        }
        return features
    except Exception as e:
        print(f"Error processing {file_path}: {str(e)}")
        # Return minimal features for failed files
        return {
            'length': 0,
            'num_lines': 0,
            'num_spaces': 0,
            'num_tabs': 0,
            'num_commands': 0,
            'num_urls': 0,
            'num_ips': 0,
            'num_hex': 0,
            'num_base64': 0,
            'content': '',
            'is_binary': 1
        }

def prepare_data(data_dir):
    """Prepare the dataset from the directory structure."""
    X = []
    y = []
    
    for file_type in ['bat', 'js', 'ps1']:
        type_dir = os.path.join(data_dir, file_type)
        if not os.path.exists(type_dir):
            continue
            
        # Process benign files
        benign_dir = os.path.join(type_dir, 'benign')
        if os.path.exists(benign_dir):
            for file in os.listdir(benign_dir):
                if file.endswith(f'.{file_type}'):
                    features = extract_features(os.path.join(benign_dir, file))
                    if features:
                        X.append(features)
                        y.append(0)  # 0 for benign
        
        # Process malware files
        malware_dir = os.path.join(type_dir, 'malware')
        if os.path.exists(malware_dir):
            for file in os.listdir(malware_dir):
                if file.endswith(f'.{file_type}'):
                    features = extract_features(os.path.join(malware_dir, file))
                    if features:
                        X.append(features)
                        y.append(1)  # 1 for malware
    
    return X, y

def train_model(X, y):
    """Train the malware classification model."""
    # Convert features to DataFrame
    df = pd.DataFrame(X)
    
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(
        df['content'], y, test_size=0.2, random_state=42
    )
    
    # Vectorize the content
    vectorizer = TfidfVectorizer(
        max_features=1000,
        stop_words='english',
        ngram_range=(1, 3)
    )
    
    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)
    
    # Train the model
    model = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        class_weight='balanced'
    )
    
    model.fit(X_train_vec, y_train)
    
    # Evaluate the model
    y_pred = model.predict(X_test_vec)
    print("\nModel Evaluation:")
    print(classification_report(y_test, y_pred))
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    
    return model, vectorizer

def main():
    data_dir = "data"
    
    print("Preparing dataset...")
    X, y = prepare_data(data_dir)
    
    if not X or not y:
        print("No data found. Please check your data directory structure.")
        return
    
    print(f"Total samples: {len(X)}")
    print(f"Malware samples: {sum(y)}")
    print(f"Benign samples: {len(y) - sum(y)}")
    
    print("\nTraining model...")
    model, vectorizer = train_model(X, y)
    
    # Save the model and vectorizer
    os.makedirs("models", exist_ok=True)
    joblib.dump(model, "models/malware_classifier.joblib")
    joblib.dump(vectorizer, "models/vectorizer.joblib")
    print("\nModel saved to models/malware_classifier.joblib")

if __name__ == "__main__":
    main() 